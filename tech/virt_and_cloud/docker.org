#+TAGS: virtualization container docker linux_containers


* Docker
HomePage: [[https://www.docker.com/][docker.com]]
CheatSheet: [[https://github.com/wsargent/docker-cheat-sheet][github.com/docker-cheat-sheet]]
* Files
/var/lib/docker         - data and metadata store
/var/lib/containers     - long hashes are the container names these contain data on the conatiners
/var/lib/docker/image   - 
/var/lib/docker/network -
/var/lib/docker/overlay -
/var/lib/docker/plugins -
/var/lib/docker/swarm   - 
/var/lib/docker/tmp     -
/var/lib/docker/trust   -
/var/lib/docker/volumes -
/var/run/docker.pid
/var/run/docker.sock
~/.docker/config.json - this contains the dockerhub login creds

* Cmds
- docker-compose

* Tools
- [[file://home/crito/org/tech/virt_and_cloud/kubernetes.org][Kubernetes]]
- [[https://github.com/Yelp/dockersh][Dockersh]]
- [[https://github.com/kevana/ui-for-docker][DockerUI]]
- [[https://github.com/shipyard/shipyard][Shipyard]]
- [[https://github.com/gliderlabs/logspout][Logspout]]
- Swarm
** [[https://github.com/jpetazzo/dind][DIND - Docker Inside Docker]] 

* Description
* Usage
- viewing man pages for docker cmds replace an hyphen where there's a space 
#+BEGIN_SRC sh
man docker-network-create
#+END_SRC
docker network create

** Show Docker information
- show version short
#+BEGIN_SRC sh
docker --version
#+END_SRC

- show version full
#+BEGIN_SRC sh
docker version
#+END_SRC

- show detailed information about the daemon
#+BEGIN_SRC sh
docker info
#+END_SRC
** Start and Stop Containers - Container Basics
*** Start - run
- starting a docker container that is running a command
#+BEGIN_SRC sh
docker run -it ubuntu:xenial /bin/bash
#+END_SRC
i - interactive
t - attach to my terminal/tty

- run a container in the background
#+BEGIN_SRC sh
docker -d --name test_container httpd
#+END_SRC
d - detattched

- start the container but without specifying the cmd
#+BEGIN_SRC sh
docker start nginx:latest
#+END_SRC

- start a continer with a specific name
#+BEGIN_SRC sh
docker run -it --name test_container centos:6 /bin/bash
#+END_SRC

- start a container with an environment variable
#+BEGIN_SRC sh
docker run -it --env MYVAR=what_now --name test_container centos:6 /bin/bash
#+END_SRC

*** Stop
#+BEGIN_SRC sh
docker stop $DOCKER_ID
#+END_SRC

*** Restart
#+BEGIN_SRC sh
docker restart $DOCKER_ID
#+END_SRC

*** Pause
#+BEGIN_SRC sh
docker pause $DOCKER_ID
#+END_SRC

*** Unpause
#+BEGIN_SRC sh
docker unpause $DOCKER_ID
#+END_SRC

*** Kill
Sends SIGKILL to a running container    
#+BEGIN_SRC sh
docker kill $DOCKER_ID
#+END_SRC

*** Run single cmd with a container
#+BEGIN_SRC sh
docker run ubuntu:xenial /bin/echo "Hello from this container"
#+END_SRC
once the container has run the command it will exit

** Pull an Image from a Registry
- pull each images and each tag
#+BEGIN_SRC sh
docker pull -a hello-world
#+END_SRC

- pull an images that hasn't been confirmed to be safe by the repo
#+BEGIN_SRC sh
docker pull --disable-content-trust hello-world
#+END_SRC

** Removing containers
- remove conatiner from memory
#+BEGIN_SRC sh
docker rm ae884abc2ba1
#+END_SRC

- remove multiple containers from memory
#+BEGIN_SRC sh
docker rm ae884abc2ba1 name_of_container 39efceafa4f0
#+END_SRC
you can mix container names with ids, just delimit with a space

- remove all containers that are in memory
#+BEGIN_SRC sh
docker rm $(docker ps -a -q)
docker rm `docker ps -a -q`
#+END_SRC

- force kill a running container
#+BEGIN_SRC sh
docker rm -f 39efceafa4f0
#+END_SRC
this will kill the container process and remove the container from memory

- remove container by deleting file on the filesystem
#+BEGIN_SRC sh
systemctl stop docker
cd /var/lib/docker/containers
rm -rf 39efceafa4f084ccc495b4eb40af351eb66029c4091723eae16ca38299fede93
#+END_SRC
this would remove the container from docker, and won't be present when docker is restarted

- running a temporary container
#+BEGIN_SRC sh
docker run -it --rm --name test_container centos:6 /bin/bash
#+END_SRC
now when you quit it will remove the container from memory

** Removing Base Images
- remove a base image
#+BEGIN_SRC sh
docker rmi ubuntu:xenial
#+END_SRC
this will only work if there aren't currently any containers in memory that use the base image

- remove a base image even if containers based on image
#+BEGIN_SRC sh
docker rmi -f ubuntu:xenial
#+END_SRC
containers in memory will still be available to use

** List containers
- list all running containers
#+BEGIN_SRC sh
docker ps
#+END_SRC

- list all containers that are still present in memory
#+BEGIN_SRC sh
docker ps -a
#+END_SRC

** List images
- list all images
#+BEGIN_SRC sh
docker images --all
docker images -a
docker images
#+END_SRC

- list all the digests of the images
#+BEGIN_SRC sh
docker images --digests
#+END_SRC

- filter by creation 
#+BEGIN_SRC sh
docker images --filter "before=centos:6"
#+END_SRC
this will print to the screen all images that were created before the "centos:6" image

- list all images with full images ID
#+BEGIN_SRC sh
docker images --no-trunc
#+END_SRC

- show only image ids
#+BEGIN_SRC sh
docker images --quiet
#+END_SRC

** Search docker hub from the cmd line
- search for all apache images
#+BEGIN_SRC sh
docker search apache
#+END_SRC
this will return a list of all the images that contain apache in their description

- limit the number of responses
#+BEGIN_SRC sh
docker search --filter stars=50 apache
#+END_SRC
this will now only return images that have 50> stars

- only show images that are official releases
#+BEGIN_SRC sh
docker search --filter is-official=true apache
#+END_SRC

- get the top ten images
#+BEGIN_SRC sh
docker search --limit 10 apache
#+END_SRC
** Tagging an image
- tag an image with my own tag
#+BEGIN_SRC sh
docker tag centos:6 mycentos:v1
#+END_SRC
this will create a duplicate of the original centos:6

** Managing images
- show the build history of a file
#+BEGIN_SRC sh
docker image history httpd:latest
#+END_SRC
this will show the build layers of the image

- tar up an image to move to another machine/storage
#+BEGIN_SRC sh
docker image save centos:6 > mycentos.custom.tar
#+END_SRC

- importing a tared image
#+BEGIN_SRC sh
docker import mycentos.custom.tar localimport:centos6
#+END_SRC
this will allow us to set a new name:tag

- load a tared image
#+BEGIN_SRC sh
docker load --input mycentos.custom.tar
#+END_SRC
this will assign the original name:tag

- listing images
#+BEGIN_SRC sh
docker image ls
#+END_SRC
same as "docker images"

** Inspecting an image
- view all information of an image
#+BEGIN_SRC sh
docker image inspect centos:6
#+END_SRC
this will print a large json document to the screen

- search for specific property
#+BEGIN_SRC sh
docker image inspect centos:6 --format '{{.ContainerConfig.Hostname}}'
#+END_SRC

- search for all properties in a section
#+BEGIN_SRC sh
docker image inspect centos:6 --format '{{.ContainerConfig}}'
#+END_SRC
This will just print all properties without their keys

- search for all properties of a section and add the keys
#+BEGIN_SRC sh
docker image inspect centos:6 --format '{{json .ContainerConfig}}'
#+END_SRC

** Get logs from container
#+BEGIN_SRC sh
docker logs $DOCKER_ID
#+END_SRC
this will provide a print out of the activity in the container

** Info on a Containerss
- overview
#+BEGIN_SRC sh
docker ps $DOCKER_ID
#+END_SRC

- view only running containers
#+BEGIN_SRC sh
docker ps
#+END_SRC

- view all containers that are stored in memory
#+BEGIN_SRC sh
docker ps -a
#+END_SRC

- more detailed view
#+BEGIN_SRC sh
docker inspect name_of_container
#+END_SRC

- docker top
#+BEGIN_SRC sh
docker top name_of_container
#+END_SRC
this provides an updated overview of the container dynamically

- view events over a period of time
#+BEGIN_SRC sh
docker events --since '1h'
#+END_SRC

** Inspect
- inspect a running container
#+BEGIN_SRC sh
docker container inspect testweb
#+END_SRC
though the word "container" could be emitted, as docker has grown with my other tools sometime you my have to be specific

- pulling specific properties
#+BEGIN_SRC sh
docker container inspect --format="{{json .State}}" testweb
#+END_SRC

** Pruning
- clean up the docker instance
#+BEGIN_SRC sh
docker system prune
#+END_SRC
- The message below will be displayed and aking would you like to continue
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
	  
- clean up the system and volumes
#+BEGIN_SRC sh
docker system prune --volumes
#+END_SRC
you would get the same warning message as above, but warning that volumes not being used will also be removed

- Clean up non-used network interfaces
#+BEGIN_SRC sh
docker network prune
#+END_SRC

** Interacting with a running instance
- attach, makesure that a shell is available, or you'll attach to the processes
#+BEGIN_SRC sh
docker attach name_of_container
#+END_SRC
this method will cause the container to exit when you exit

- exec, this command always for any command to be run by against the container
#+BEGIN_SRC sh
docker exec ecstatic_yonath /bin/cat /etc/profile
#+END_SRC
this will print to the screen the /etc/profile of the container

- some instances run with a non-priviledged user. To connect as root run
#+BEGIN_SRC sh
docker exec -u 0 -it peaceful_raman /bin/bash
#+END_SRC
this will also not kill the container when root exits
u - user
0 - root

- connect with exec to ensure that the container doesn't stop on exit
#+BEGIN_SRC sh
docker exec -i -it peaceful_raman /bin/bash
#+END_SRC
this will mean that another instance of bash is running on the system and when exited it won't stop

** Saving changes to a base image
- start the the container
#+BEGIN_SRC sh
docker run -it ubuntu:xenial /bin/bash
#+END_SRC
i - interactive
t - attached to terminal
  
- make the required changes
#+BEGIN_SRC sh
apt-get update
apt-get install telnet ssh
adduser test
#+END_SRC
changes have now been made

- now exit the container
#+BEGIN_SRC sh
exit
#+END_SRC

- confirm that the container has stopped  
#+BEGIN_SRC sh
docker ps
#+END_SRC
this instance shouldn't be present

- now commit the changes to the image file
#+BEGIN_SRC sh
docker commit -m "Installed Telnet, SSH, and added the user test" -a "frank@gmail.com" pedantic_jepsen ubuntusshd:v1
#+END_SRC
m - commit message
a - author
pedantic_jepsen is the image name given by docker
frank/buntusshd:v1 is the new image name

- view docker images
#+BEGIN_SRC sh
docker images
#+END_SRC
frank/ubuntusshd:v1 should now be an option

** List and Inspect Networking
- view all container networks
#+BEGIN_SRC sh
docker network ls
#+END_SRC
this will give a truncated network id

- to view container network id non-truncated
#+BEGIN_SRC sh
docker network ls --no-trunc
#+END_SRC

- more detailed network information
#+BEGIN_SRC sh
docker network inspect bridge
#+END_SRC

** Networking
- Create a simple bridge network
#+BEGIN_SRC sh
docker network create --subnet 10.1.0.0/24 --gateway 10.1.0.1 mybridge01
#+END_SRC

- Delete a network
  - never remove the default networks
  - if these are removed usually easier to reinstall docker from scratch

- removing a network
#+BEGIN_SRC sh
docker network rm mybridge01
#+END_SRC
mybridge01 - this is the name of the network to remove

- a more complex network that sets a subnet, and then assigns a subset of the subnet that can be used
#+BEGIN_SRC sh
docker network create --subnet 10.1.0.0/16 --gateway 10.1.0.1 --ip-range=10.1.4.0/24 --driver=bridge --label=host4network bridge04
#+END_SRC
driver - specifies what type of interface to use

- add a container to the network
#+BEGIN_SRC sh
docker run -it --name nettest1 --net bridge04 centos:latest /bin/bash
#+END_SRC

- specify the ip that a containr should have
#+BEGIN_SRC sh
docker run -it --name nettest1 --net bridge04 --ip 10.1.4.100 centos:latest /bin/bash
#+END_SRC

- show currently bound ports
#+BEGIN_SRC sh
docker port serene_hodgkin
#+END_SRC

- exposing a port to the host
#+BEGIN_SRC sh
docker run -itd -p 80 nginx:latest
#+END_SRC
this will use one the default ports on the host machine to bind 80

- exposing the default ports
#+BEGIN_SRC sh
docker run -itd -P nginx
#+END_SRC
this will bind the ports that were set to expose in the image to a default port of the host

- bind a port to localhost
#+BEGIN_SRC sh
docker run -itd -p 127.0.0.1:8081:80 nginx:latest
#+END_SRC
this now bind only localhost:8081 to port 80 of nginx

- Setting dns for the container
#+BEGIN_SRC sh
docker run -it --dns=8.8.8.8 --name mycontainer1 ubuntu:latest /bin/bash
#+END_SRC

- Setting dns and search domain
#+BEGIN_SRC sh
docker run -it --dns=8.8.8.8 --dns-serach="mydomain.local" --name="mycontainer1" ubuntu:latest /bin/bash
#+END_SRC

** Mounting Volumes
- mount a volume that is on the host on the container
#+BEGIN_SRC sh
docker run -it --name="local_vol" -v /home/user/docker/mydata:/mydata centos:latest /bin/bash
#+END_SRC

** Naming Containers
- set our own name for the container
#+BEGIN_SRC sh
docker run -itd --name webtest1 nginx:latest
#+END_SRC

- rename a container
#+BEGIN_SRC sh
docker rename webtest1 nginx1
docker rename 2f201820d435 nginx1
#+END_SRC
This can be done on both stopped and running containers

** Pushing to DockerHub
- login
#+BEGIN_SRC sh
docker login
#+END_SRC
this will then prompt you for your username and password

- tag docker image that is to be pushed with the created repo on dockerhub
#+BEGIN_SRC sh
docker tag centos7/apache:v1 alickmitchell/customapache
#+END_SRC

- now push to repo
#+BEGIN_SRC sh
docker push alickmitchell/customapache
#+END_SRC

- logout
#+BEGIN_SRC sh
docker logout
#+END_SRC

** Setting the storage driver
Check the documentation for wich driver is currently support for the distro that you are using
  - ubuntu - aufs
  - centos/rhel - devicemapper
  - sles - btrfs

- create /etc/docker/daemon.json
#+BEGIN_EXAMPLE
{
  "storage-driver":"devicemapper"
}
#+END_EXAMPLE
this will create /var/lib/docker/devicemapper, this will be the new location where images are placed
  - an images that you want to retain will need to be exported before you restart the service, otherwise they will be lost

- restart the docker service
#+BEGIN_SRC sh
systemctl restart docker.service
#+END_SRC

*** What storage driver am I using
#+BEGIN_SRC sh
docker info | grep -i storage
#+END_SRC

** Configuring the logging driver
- json is usally set as the default, but there are other options
  - none
  - json-file
  - syslog
  - journald
  - gelf
  - fluentd
  - awslogs
  - splunk
  - etwlogs
  - gcplogs
  - logentries
    
- edit /etc/rsyslog.conf uncomment or add
#+BEGIN_EXAMPLE
# Provides UDP syslog reception
$ModLoad imudp
$UDPServerRun 514
#+END_EXAMPLE

- restart the rsyslog service
#+BEGIN_SRC sh
systemctl restart rsyslog.service
#+END_SRC

- edit /etc/docker/daemon.json we will set syslog 
#+BEGIN_EXAMPLE
{
  "log-driver": "syslog",
  "log-opts": {
          "syslog-address": "udp://172.31.125.216:514"
  }
}
#+END_EXAMPLE
ip address being the private ip address and the port the one that was configured in /etc/rsyslog.conf

- restartt the docker service
#+BEGIN_SRC sh
systemctl restart docker.service
#+END_SRC

- confirm that the logging driver has been changed
#+BEGIN_SRC sh
docker info | grp -i logging
#+END_SRC

** Setting logging at container level
- setting a differnt logging driver for a specific container
#+BEGIN_SRC sh
docker container run -d --name testcontainer --log-driver json-file httpd
#+END_SRC

* Installation on CentOS 7
- first create a repo file to /etc/yum.repos.d/docker.repo
#+BEGIN_EXAMPLE
[dockerrepo]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
#+END_EXAMPLE

- now update the system
#+BEGIN_SRC sh
yum update
#+END_SRC
care should be taken if this is a production server as it will update the whole system

- install the docker-engine
#+BEGIN_SRC sh
yum install docker-engine
#+END_SRC

- enable, start, and confirm status of docker
#+BEGIN_SRC sh
systemctl enable docker
systemctl start docker
systemctl status docker
#+END_SRC

- check that you are able to connect to the docker deamon
#+BEGIN_SRC sh
docker --version
#+END_SRC

- any users that are to use docker will need to be part of the docker group
#+BEGIN_SRC sh
usermod -a -G docker user
#+END_SRC
this is due to the user will need access to /var/run/docker.socket that has privs of root:docker

- confirm that the user can connect to the daemon
#+BEGIN_SRC sh
docker --version
#+END_SRC
if this fails exit the session and re-enter, this should resolve the problem

- good quick test is to pull in a simple image to docker as user
#+BEGIN_SRC sh
docker run hello-world
#+END_SRC
this will pull the hello-world image from docker hub, print a blurb and exit

* Complete Docker Installation on RHEL7
- install required packages
#+BEGIN_SRC sh
yum install -y device-mapper-persistent-data lvm2 yum-utils
#+END_SRC
yum-utils is for yum-config-manager

- add the stable repo
#+BEGIN_SRC sh
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum update
#+END_SRC

- for bledding edge
#+BEGIN_SRC sh
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo --enable docker-ce-edge.repo
yum update
#+END_SRC

- install docker
#+BEGIN_SRC sh
yum install -y docker-ce
#+END_SRC

- add users that require to access docker to the docker group 
#+BEGIN_SRC sh
usermod -aG docker user1
usermod -aG docker user2
usermod -aG docker user3
#+END_SRC
access is required to the /var/run/docker.sock file that has perms root:docker

- enable docker service
#+BEGIN_SRC sh
systemctl enable docker.service
systemctl start docker.service
systemctl status docker.service
#+END_SRC

* Complete Debian Installation on Debian
- add required packages
#+BEGIN_SRC sh
apt-get install apt-transport-https ca-certificates curl software-properties-common
#+END_SRC

- add the gpg key for docker repo
#+BEGIN_SRC sh
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
#+END_SRC

- add the repo
#+BEGIN_SRC sh
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"
apt-get update
#+END_SRC

- for ubuntu
#+BEGIN_SRC sh
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
apt-get udpate
#+END_SRC

- install the docker community edition
#+BEGIN_SRC sh
apt-get install docker-ce
#+END_SRC

- add the required users to the docker group
#+BEGIN_SRC sh
usermod -aG docker user1
usermod -aG docker user2
usermod -aG docker user3
#+END_SRC

- enable and start the service
#+BEGIN_SRC sh
systemctl enable docker.service
systemctl start docker.service
systemctl status docker.service
#+END_SRC

* Dockerfiles
- using a different name than "Dockerfile"
#+BEGIN_SRC sh
docker build -t myubuntu:v1 --file myfile .
docker build -t myubuntu:v1 -f myfile .
#+END_SRC

- build without caching
#+BEGIN_SRC sh
docker build --pull --no-cache --squash -t optimized:v1
#+END_SRC
if the image was to be rebuilt it would have no cache to speed it up
-- squash - this is only available with the experimental features of docker (normally not found in produciton)

** Simple example where ubuntu has a few packages installed
#+BEGIN_SRC sh
# This is a custom ubuntu image with ssh already installed
FROM ubuntu:xenial
MAINTAINER fflintstone<fflintstone@gmail.com>
RUN apt-get update -y
RUN apt-get install -y telnet openssh-server
#+END_SRC

- building the image
#+BEGIN_SRC sh
docker build -t="fflintstone/ubuntusshdonly:v2" .
#+END_SRC
. - if not being run in the same directory a redirect to the Dockerfile location would take the place of the "."

** Dockerfile Order of execution
Docker files run from top to bottom linearly
#+BEGIN_EXAMPLE
# Dockerfile based on the latest CentOS 7 images - non-privileged user entry
# FROM always needs to be at the top
FROM centos:latest
MAINTAINER mitchell.alick@gmail.com

# If root isn't being used the new user needs to be created
RUN useradd -ms /bin/bash user
RUN echo "EXPORT 192.168.0.0/24" >> /etc/exports.list

USER user

# If the cmd below is run then the build would fail due to the order. It would be run as user
#RUN echo "EXPORT 192.168.0.0/24" >> /etc/exports.list
#+END_EXAMPLE
if the echo cmd was run after USER user then the build would fail, as it would be run with user's privs

** Dockerfile Env
we install java 8 and then show how to set env variables for users or system-wide
#+BEGIN_EXAMPLE
# Dockerfile based on the latest CentOS 7 images - non-privileged user entry
# FROM always needs to be at the top
FROM centos:latest
MAINTAINER mitchell.alick@gmail.com

# If root isn't being used the new user needs to be created
RUN useradd -ms /bin/bash user

# all cmds need to be configured to run without user interaction
RUN yum update -y
RUN yum install -y net-tools wget

RUN cd ~ && wget --no-cookies --no-check-certificate --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm

RUN yum localinstall -y ~/jdk-8u131-linux-x64.rpm

USER user

#This will set the user to have the environment variable for JAVA_HOME
RUN cd ~ && echo "export JAVA_HOME=/usr/java/jdk1.8.0_131/jre" >> /home/user/.bashrc

#This is how to set system-wide env variables
ENV JAVA_BIN /usr/java/jdk1.8.0_131/jre/bin
#+END_EXAMPLE

** Difference between CDM and RUN
RUN is used during container build
CDM is run when the container is started
#+BEGIN_EXAMPLE
# Dockerfile based on the latest CentOS 7 images - non-privileged user entry
# FROM always needs to be at the top
FROM centos:latest
MAINTAINER mitchell.alick@gmail.com

RUN useradd -ms /bin/bash user

CMD "echo" "This is a custom container"

USER user
#+END_EXAMPLE
everytime this container is started the message "This is a custome container" will be printed to the screen

** ENTRY difference to CDM
#+BEGIN_EXAMPLE
# Dockerfile based on the latest CentOS 7 images - non-privileged user entry
# FROM always needs to be at the top
FROM centos:latest
MAINTAINER mitchell.alick@gmail.com

RUN useradd -ms /bin/bash user

ENTRYPOINT echo "This command will display this message on EVERY container that is run from it"

USER user
#+END_EXAMPLE
We used CDM before to echo a message to screen, the difference is that we can change the behaviour of CDM, but will always print this message.

** EXPOSE
#+BEGIN_EXAMPLE
# This image is based on CentOS 7 and will start apache sservice in each container
FROM centos:latest
MAINTAINER alickmitchell@example.com

RUN yum update -y
RUN yum install -y httpd net-tools

RUN echo "This is a custom index file built during the image creation" > /var/www/html/index.html

# This will mean that when the -P option is enabled when the container starts 80 will be mapped to a default port
EXPOSE 80

ENTRYPOINT apachectl "-DFOREGROUND"
#+END_EXAMPLE
Without the EXPOSE, ports have to be explicitly selected at the cmd line by docker on creation of the container

** LA Docker Cert Associate - Dockerfile1
#+BEGIN_EXAMPLE
# Tihs is our first Dockerfile
ARG TAGVERSION=6
FROM centos:${TAGVERSION}

LABEL maintainer="fred_flintstone@example.com"

RUN yum update -y && \
	yum install httpd net-tools -y && \
	mkdir -p /run/httpd && \
	rm -rf /run/http/* /tmp/httpd*
	
COPY index.html /var/www/html/

CMD echo "Remember to check your container IP Address"

ENV ENVIRONMENT="production"

VOLUME /mymount

EXPOSE 80

ENTRYPOINT apachectl "-DFOREGROUND"
#+END_EXAMPLE

** Modify an image to a single layer
- docker sqush - is an external tool that can be used
Github: https://github.com/jwilder/docker-squash
  
- using docker
#+BEGIN_SRC sh
docker run --name testcontainer mybuild:v4
docker ps -a
docker export testcontainer > mybuild4.tar
docker import mybuild4.tar mybuild:importv5
#+END_SRC
though it's not possible to squash an image to one layer with the docker client it does reduce the size

* Universal Control Plane (UCP) System Requirements

ports
  - managers, workers -  incomming TCP 443   - Port for the UCP web UI and API
  - managers          -  incomming TCP 2376  - Port for the Docker Swarm manager, used for backwards compatibility
  - managers          -  incomming TCP 2377  - Port for communication between swarm nodes
  - workers           -  out-going TCP 2377  - Port for communication between swarm nodes
  - managers, workers -  in/out    UDP 4789  - Port for overlay networking
  - managers, workers -  in/out TCP/UDP 7946 - Port for gossip based networking
  - managers, workers -  incomming TCP 12376 - Port for TLS proxy that provides access to UCP, Docker Engine and Docker Swarm
  - managers,         -  in        TCP 12379 - Port for internal node configuration, cluster configuration and HA
  - managers,         -  in        TCP 12380 - Port for internal node configuration, cluster configuration and HA
  - managers,         -  in        TCP 12381 - Port for the Certificate Authority
  - managers,         -  in        TCP 12382 - Port for the UCP Cert Auth
  - managers,         -  in        TCP 12383 - Port for the authentication storage backend
  - managers,         -  in        TCP 12384 - Port for the authentication storage backend for replication across managers
  - managers,         -  in        TCP 12385 - Port for the authentication service API
  - managers,         -  in        TCP 12386 - Port for the authentication worker
  - managers,         -  in        TCP 12387 - Port for the metrics service
    
- Minimum Requirements
  - 8gb RAM (Managers or DTR Nodes)
  - 4gb RAM (Workers)
  - 3gb Free Disk
    
- Recommaneded Requirements
  - 16gb RAM (Managers or DTR Nodes)
  - 4vCPUs (Workers or DTR Nodes)
    
* Set Up and Configure UCP and Docker Trusted Repository (DTR) for Secure Cluster Management
- we need our cluster build first

- now install ucp container on Manager node
#+BEGIN_SRC sh
docker container run --rm -it --name ucp -v /var/run/docker.sock:/var/run/docker.sock docker/ucp:2.2.4 install --host-address 172.31.116.158 --interactive
#+END_SRC
you will be prompted for a few answers  - managers,         -  in        TCP 12379 - Port for internal node configuration, cluster configuration and HA

#+BEGIN_EXAMPLE
Admin Username: admin
Admin Password:
You may enter additional aliases (SANs) now or press enter to proceed with the above list
Additional aliases: ucp.example.com
#+END_EXAMPLE

- if doing this in the LA labs, edit the /etc/hosts file so that the hostnames are set to their private ip addrs
#+BEGIN_EXAMPLE
172.31.116.158 fredflintstone1.mylabserver.com
172.31.116.158 ucp.example.com
172.31.116.18 fredflintstone2.mylabserver.com
172.31.116.18 dtr.example.com
172.31.16.108 fredflintstone3.mylabserver.com
#+END_EXAMPLE

- now the UCP will be available, this can be connected to with https://ucp.example.com/login
  
- add the license

- DTR is found in the Admin Settings
  - choose the node you want to install DTR on in the dropdown menu
    
- the command to install DTR
#+BEGIN_SRC sh
docker run -it --rm docker/dtr install --ucp-node fredflintstone2.mylabserver.com --ucp-username admin --ucp-url https://fredflintstone1.mylabserver.com --ucp-insecure-tls
#+END_SRC

* Networking
- view the overall docker network
#+BEGIN_SRC sh
docker network ls
#+END_SRC

- detailed view of the docker network
#+BEGIN_SRC sh
docker network inspect bridge
#+END_SRC
this will provide the usual inspect json view

- setting the network of the container
#+BEGIN_SRC sh
docker run -d --name testweb -p 80:80 --network=devel1 httpd
#+END_SRC

- add a running container to a network
#+BEGIN_SRC sh
docker network connect --ip=192.168.1.10 devel0 testweb
#+END_SRC
devel0 - this is the network name

- remove a container from a network
#+BEGIN_SRC sh
docker network disconnect devel0
#+END_SRC

- create a bridge and confirm creation
#+BEGIN_SRC sh
docker network create --driver=bridge --subnet=192.168.1.0/24 --opt "com.docker.network.driver.mtu"="1501" devel0
docker network ls
docker network inspect devel0
#+END_SRC

** Network Drivers
- Bridge
  - Simple to use, trobleshott and is the default on stand-alone Docker hosts
  - Consists of a private network that is internal to the host system; all containers implemented on thsi host using Bridge networking can communicate
  - External access is granted by port exposure of the container's services and accessed by the host or static routes added with the host as the gateway for that network

- None
  - Used when the container needs absolutely no networking access at all
  - Containers operating on this driver can onlly be accessed on the host they are running on.
  - These containers can be attached to directley or with the relevent docker cmd(exec or attach).

- Host
  - Sometimes referred to as 'Host Only Networking'
  - Only accessible via the underlying host
  - Access to servicees can only be provided by exposing container service ports to the host system

- Overlay
  - Allow communication among all Docker Daemons that are participating in a Swarm
  - It is a 'Swarm Scope' driver in that it extends itself(building previoulsy non-existent networks on Workers if needed) to all daemons in the Swarm cluster
  - Allows the communication of multiple services that may have replicas running on any number of workers in the Swarm, regardless of their origin or destination.
  - Default mode of Swarm communication

- Ingress
  - Special overlay network that load balances network traffic amongst a given service's working nodes. 
  - Maintains a list of all IP addresses from nodes that participate in that service (using the IPVS module) and when a request comes in, routes to one of them for the indicated service.
  - Provides the 'routing mesh' that allows services to be exposed to the external network without having a replica running on every node in the Swarm.

- Docker Gateway Bridge
  - Special bridge network that allows onverlay networks (including Ingress) access to an indvidual Docker daemon's physical network
  - Every container run within a service is connected to the local Docker daemon's host network.
  - Automatically created when a Swarm is initialized or joined.

** Publishing ports
- this will look at the image and use the information provided there
#+BEGIN_SRC sh
docker run -d --name testweb -P httpd
docker ps
#+END_SRC
this will bind the container port to a host port above 32768

- specify on the cmd line which ports to map 
#+BEGIN_SRC sh
docker run -d --name testweb -p 80:80 httpd
docker run -d --name testweb --publish 80:80 httpd
#+END_SRC

** Overlay Network
These networks allow all nodes in a swwarm to communicate, but can't be accessed from outside of the network. 

- configure the network
#+BEGIN_SRC sh
docker network create --driver=overlay --subnet=192.168.1.0/24 overlay0
#+END_SRC

- confirm
#+BEGIN_SRC sh
docker network ls
docker network inspect overlay0
#+END_SRC

- creating a service using the overlay network
#+BEGIN_SRC sh
docker service create --name testweb -p 80:80 --network=overlay0 --replicas 3 httpd
#+END_SRC
this will propagate the overlay0 network to the other nodes in the swarm

** Setting DNS
- setting dns on a container
#+BEGIN_SRC sh
docker run -d --name testweb --dns=8.8.8.8 --dns=8.8.4.4 httpd
#+END_SRC

- set docker configuration to use a different DNS with all containers
/etc/docker/daemon.json
#+BEGIN_EXAMPLE
{
	"dns": ["8.8.8.8", "8.8.4.4"]
}
#+END_EXAMPLE
the service will have to be restarted for these changes to take effect

* Secure Registry
** Setting up a Docker Secure Registry
- install openssl for cert creation
#+BEGIN_SRC sh
yum install -y openssl
#+END_SRC

- create auth and certs directories
#+BEGIN_SRC sh
mkdir ~/auth ~/certs
#+END_SRC

- create a self signed certificate
#+BEGIN_SRC sh
openssl req -newkey rsa:4096 -nodes -sha256 -keyout certs/dockerrepo.key -x509 -days 365 -out certs/dockerrepo.crt -subj /CN=myregistrydomain.com
#+END_SRC

- add entry to /etc/hosts
#+BEGIN_EXAMPLE
172.31.22.115 myregistrydomain.com
#+END_EXAMPLE
this wouldn't not be need in production as DNS would be configured for your domain

- make directory to hold certificate
#+BEGIN_SRC sh
mkdir -p /etc/docker/certs.d/myregistrydomain.com:5000
#+END_SRC

- copy the created certificate from earlier
#+BEGIN_SRC sh
cp /home/user/certs/dockerrepo.crt /etc/docker/certs.d/myreistrydomain.com:5000/ca.crt
#+END_SRC
ensure that ownership is root:root

- now pull the registry container
#+BEGIN_SRC sh
docker pull registry:2 
#+END_SRC

- now run the registry container
#+BEGIN_SRC sh
docker run --entrypoint htpasswd registry:2 -Bbn test password > auth/htpasswd
#+END_SRC
this will create a hash password to use to connect to the registry

- Deploy
#+BEGIN_SRC sh
docker run -d -p 5000:5000 -v /home/user/certs:/certs -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/dockerrepo.crt -e REGISTRY_HTTP_TLS_KEY=/certs/dockerrepo.key -v /home/user/auth:/auth -e REGISTRY_AUTH=htpasswd -e REGISTRY_AUTH_HTPASSWD_REALM="Registry Realm" -e REGISTRY_AUTH_HTPASSWD=/auth/htpasswd registry:2
#+END_SRC

- tag an image to be used by our registry
#+BEGIN_SRC sh
docker tag busybox myregistrydomain.com:5000/my-busybox
#+END_SRC

- Log into the registry
#+BEGIN_SRC sh
docker login myregistrydomain.com:5000/my-busybox
#+END_SRC
prompted for username and password set earlier

- now push the image to the registry
#+BEGIN_SRC sh
docker push myregistrydomain.com:5000/my-busybox
#+END_SRC

- confirm that the registry took the image
#+BEGIN_SRC sh
docker rmi busybox
docker rmi myregistrydomain.com:5000/my-busybox
#+END_SRC
this remove the busybox image from our system, but not from the registry container

- pull the busybox image from the registry container
#+BEGIN_SRC sh
docker pull myregistrydomain.com:5000/my-busybox
#+END_SRC

** Managing Images in the Registry
- view what is in the registry
#+BEGIN_SRC sh
curl --insecure -u "test:password" https://myregistrydomain.com:5000/v2/_catalog
#+END_SRC
insecure is used as we set up our registry with a self signed cert

- push an image to the registry
#+BEGIN_SRC sh
docker login myregistrydomain.com:5000
docker tag centos:6 myregistrydomain.com:5000/my-centos
docker push myregistrydomain.com:/my-centos
#+END_SRC

- using wget to view the catalog
#+BEGIN_SRC sh
wget --no-check-certificate --http-user=test --http-password=password https://myregistrydomain.com:5000/v2/_catalog
#+END_SRC
this will pull the catalog as a file

- view tags for an image
#+BEGIN_SRC sh
curl --insecure -u "test:password" https://myregistrydomain.com:5000/v2/my-busybox/tags/list
#+END_SRC

- view the json output for the image
#+BEGIN_SRC sh
curl --insecure -u "test:password" https://myregistrydomain.com:5000/v2/my-busybox/manifest/latest
#+END_SRC

** Signing images
- build the image
#+BEGIN_SRC sh
docker build -t myregistrydomain.com:5000/untrusted.latest .
#+END_SRC

- create environment variable $DOCKER_CONTENT_TRUST
#+BEGIN_SRC sh
export DOCKER_CONTENT_TRUST=1
#+END_SRC

- push the image to the repo, and because of $DOCKER_CONTENT_TRUST it will try to sign the image
#+BEGIN_SRC sh
docker push myregistrydomain.com:5000/untrusted.latest:latest
#+END_SRC
this will only sign non-self signed certs, but still push the image

- try to pull client with $DOCKER_CONTENT_TRUST=0
#+BEGIN_SRC sh
docker pull myregistrydomain.com:5000/untrusted.latest:latest
#+END_SRC
this will pull the image

- try to pull on client with $DOCKER_CONTENT_TRUST=1
#+BEGIN_SRC sh
docker pull myregistrydomain.com:5000/untrusted.latest:latest
#+END_SRC
this will fail to pull the image as the image isn't signed

* Swarm
** Setting up Swarm
- view the overview of the swarm
#+BEGIN_SRC sh
docker node ls
#+END_SRC
worker nodes will provide no output

*** Configure Managers
- initialize the swarm
#+BEGIN_SRC sh
docker swarm init --advertise-addr 172.31.16.218 
#+END_SRC
this will output a swarm token, this should be copied and stored as it's what will be used to allow nodes to join the swarm

- get token if lost (perform on a manager)
#+BEGIN_SRC sh
docker swarm join-token worker
#+END_SRC

- create another manager
#+BEGIN_SRC 
docker swarm join-token manager
#+END_SRC
this token will be used to join more manager to the swarm

*** Configure Workers
- get worker token (manager)
#+BEGIN_SRC sh
docker swarm join-token worker
#+END_SRC

- adding a node
#+BEGIN_SRC sh
docker swarm join --token SWMTKN-1-462c9jrhopn4ph11ahxo58f0qf5ibk994ek78a3lk6bowt419k-2h5q0mvijb5wk3iuho2b53nkd 172.31.100.141:2377
#+END_SRC

- Trouble shooting "Error response from daemon: rpc error: code = Unavailable desc = grpc: the connection is unavailable"
  - this error is related to firewall rules
- solution
#+BEGIN_SRC sh
firewall-cmd --add-port=2376/tcp --permanent  
firewall-cmd --add-port=2377/tcp --permanent  
firewall-cmd --add-port=7946/tcp --permanent  
firewall-cmd --add-port=7946/udp --permanent  
firewall-cmd --add-port=4789/udp --permanent
firewall-cmd --reload
#+END_SRC

*** Setting up Backup and Restore
- create a web service in the cluster, with at least 2 running at all times
#+BEGIN_SRC sh
docker srevice create --name bkupweb --publish 80:80 --replicate 2 httpd
#+END_SRC

- confirm the creation of the service
#+BEGIN_SRC sh
docker service ls
#+END_SRC
this will tell us what nodes are providing the service

- stop the docker service to create a backup
#+BEGIN_SRC sh
systemctl stop docker.service
#+END_SRC

- create a swarm backup directory
#+BEGIN_SRC sh
mkdir /root/swarm
cp -rf /var/lib/docker/swarm/ .
tar cvf swarm.tar /root/swarm/
#+END_SRC

- use the swarm.tar file to restore with a new manager node
#+BEGIN_SRC sh
systemctl stop docker.service
rm -rf /var/lib/docker/swarm/
tar xvf swarm.tar
mv swarm /var/lib/docker
systemctl start docker.service
docker swarm init --force-new-cluster
#+END_SRC

- confirm the service has restored
#+BEGIN_SRC sh
docker service ls
docker service ps bkupweb
#+END_SRC

** Steps to Lock a Cluster
- to lock the swarm
#+BEGIN_SRC sh
docker swarm update --autolock=true
#+END_SRC
this will provide a key that needs to be kept to unlock the swarm

- lost the key, but have access to a manager
#+BEGIN_SRC sh
docker swarm unlock-key
#+END_SRC

- unlock the swarm
#+BEGIN_SRC sh
docker swarm update --autolock=false
#+END_SRC

- changing the key
#+BEGIN_SRC sh
docker swarm unlock-key --rotate
#+END_SRC

** Running Services Under Swarm
- starting a service over the swarm
#+BEGIN_SRC sh
docker service create --name testweb --publish 80:80 httpd
#+END_SRC
by default it will run on a single node, no matter which node's ip is queryed the web page will be displayed

- confirm service is running
#+BEGIN_SRC sh
docker service ls
#+END_SRC
this will provide information of the running service

- stopping a service
#+BEGIN_SRC sh
docer service rm testweb
#+END_SRC

- scale up the number of replicas
#+BEGIN_SRC sh
docker service update --replicas 3 testweb
#+END_SRC

- limit the amount of CPU that is accessable
#+BEGIN_SRC sh
docker service update --limit-cpu=.5 --reserve-cpu=.75 --limit-memory=120m --reserve-memory=256m
#+END_SRC
--limit   - soft limit
--reserve - hard limit
memory can only be reserved to a low of 4m

- interact with two services
#+BEGIN_SRC sh
docker service scale --detach=false testnginx=3 testweb=3
#+END_SRC
where update only works on a single service, scale can work on many

- setting global mode
#+BEGIN_SRC sh
docker service create --name testweb -p 80:80 --mode global --detach=false httpd
#+END_SRC
global mode doesn't allow for the number of replicas to be set, but sets an instance on every node

** Viewing details of nodes
- view all details
#+BEGIN_SRC sh
docker node inspect alickmitchell4.mylabserver.com
#+END_SRC
this will output the details in json format

- view details in a more readable format
#+BEGIN_SRC sh
docker node inspect --pretty alickmitchell4.mylabserver.com
#+END_SRC

** Adding labels to nodes
- get the docker node id
#+BEGIN_SRC sh
docker node ls
#+END_SRC

- add the label to the node
#+BEGIN_SRC sh
docker node update --label-add mynode=testnode oref425j1yinimxelhlom7tbn
#+END_SRC
the string at the end is the node id

- now using the label with constraint to start a service
#+BEGIN_SRC sh
docker service create --name constraints -p 80:80 --constraint 'node.labels.mynode == testnode' --replicas 3 httpd
#+END_SRC
this would force all 3 replicas on the node that we added the label too.

** Storage and Volumes
*** Showing that files are not replicated with basic docker volumes across clusters
- view all volumes
#+BEGIN_SRC sh
docker volume ls
#+END_SRC

- create a volume
#+BEGIN_SRC sh
docker volume create my-mount
#+END_SRC

- view the details on the volume
#+BEGIN_SRC sh
docker volume inspect my-mount | less
#+END_SRC

- the location of the mount
#+BEGIN_SRC sh
cd /var/lib/docker/volumes/my-mount/_data/
echo "this is the new mount" > hostfile.txt
#+END_SRC

- create a service that uses the volume
#+BEGIN_SRC sh
docker service create --name testweb -p 80:80 --mount source=my-mount,target=/internal-mount --detach=false --replicas 3 httpd
#+END_SRC

- attach to the container
#+BEGIN_SRC sh
docker ps
docker exec -it 680c88428bd9 /bin/bash
#+END_SRC

- now check that the mount is there along with the file that we created
#+BEGIN_SRC sh
cd /internal-mount
cat hostfile.txt
#+END_SRC

- connect to the second container(on other node)
#+BEGIN_SRC sh
docker exec -it gc8lrxv18xafrcy8ebgrqcubp /bin/bash
#+END_SRC

- now check the internal-mount
#+BEGIN_SRC sh
cd /internal-mount
#+END_SRC
you will notice that there is no file

- now remove the mount
#+BEGIN_SRC sh
docker service rm testweb
docker volume rm my-mount
#+END_SRC

*** Mounting a local directory on a container
- tihs example uses the bind type, to bind a local dir to a dir in the container
#+BEGIN_SRC sh
mkdir content
echo "this is in the content dir" > content/index.html
docker run -d --name test-web -p 80:80 --mount type=bind,source=/home/user/content,target=/usr/local/apache2/htdocs httpd
docker container inspect test-web | grep -i -B3 -A3 "ipaddr"
w3m http://172.17.0.2
#+END_SRC

** Troubleshooting
- these cmds can help when nodes are not working in the correct manner
#+BEGIN_SRC sh
docker node ls
docker service ps service_name
docker service inspcet service_name
#+END_SRC

- is the cluster locked
  
- SELinux issues - try "setenforce 0"
  
- Permissions - make sure any resources that you are allocating to the container, you as the user have permissions to access (partions, mounts, volumes, files etc)
  
- CPU/Mem - does the container have the required resouces to run the containers, are you using constraints to limit cpu and members

- Routing - make sure that the end points are using the same network segment or have the necessary routing to get there
  
- Firewall - makesure that the appropriate ports and protocols are enabled to the destination IPs

** Quorum
- Manager Nodes
  - Every Swarm has 1 to N 'Manager' nodes in it.
  - they manage, direct, log and report on the lifecycle of the Swarm
    
- Raft Consensus Algorithm
  - this is used to manage the swarm state
  - it uses a 'consensus' method amongst the management nodes, that in the event of a manager node failure, any other manager node would have enough information to continue to operate the Swarm
  - Raft tolerates up to (N-1)/2 failures and requies a majority (quorum) of (N/2)+1 to agree on any new instructions that are proposed to the cluster for execution
    
| swarm | majority | fault tolerance |
|     1 |        1 |               0 |
|     2 |        2 |               0 |
|     3 |        2 |               1 |
|     4 |        3 |               1 |
|     5 |        3 |               2 |
|     6 |        4 |               2 |
|     7 |        4 |               3 |
|     8 |        5 |               3 |
|     9 |        5 |               4 |

- Manager Node Requirements
  - use static IPs
  - immediately replace failed managers
  - distribute managements nodes for HA
  - monitor Swarm health - you should know if you lose a Manager
  - have a backup and recovery plan for the Swarm
    
- Run 'Manager Ony' Nodes
#+BEGIN_SRC sh
docker node update --availability drain node_id
#+END_SRC
  
* Compose
** Convert an Application Deployment into a Stack File Using a YAML Compose File
- install required packages
#+BEGIN_SRC sh
yum install python-pip
pip install --upgrade pip
#+END_SRC

- install the compose
#+BEGIN_SRC sh
pip install docker-compose
#+END_SRC
had to uninstall "python-requests" to get it installed on centos7

- create a directory to work in
#+BEGIN_SRC sh
mkdir docker
cd docker
#+END_SRC

- create a Dockerfile
#+BEGIN_EXAMPLE
# simple webserver
FROM centos:latest
LABEL maintainer="fflintstone@example.com"

RUN yum install -y httpd
RUN echo "Our Container Website" >> /var/www/html/index.html

EXPOSE 80

ENTRYPOINT apachectl -DFOREGROUND
#+END_EXAMPLE

- build the image
#+BEGIN_SRC sh
docker build -t myhttpd:v1 .
#+END_SRC

- confirm that the image works
#+BEGIN_SRC sh
docker run -d --name testweb -p 80:80 myhttpd:v1
w3m http://192.168.10.11
#+END_SRC
the ip being the localhost

- remove the container now we know that it works
#+BEGIN_SRC sh
docker stop testweb
docker rm testweb
#+END_SRC

- create the docker compose yaml file
docker-compose.yml
#+BEGIN_EXAMPLE
---
version: '3'
services:
  apiweb1:
    image: myhttpd:v1
    build: .
    ports:
      - "81:80"
  apiweb2:
    image: myhttpd:v1
    ports:
      - "82:80"
  load-balancer:
    image: nginx:latest
    ports:
      - "80:80"
#+END_EXAMPLE

- run the compose file
#+BEGIN_SRC sh
docker-compose up -d
#+END_SRC

- confirm the creation of the containers
#+BEGIN_SRC sh
docker ps
docker-compose ps
#+END_SRC

- bring down the compose service
#+BEGIN_SRC sh
docker-compose down --volumes
#+END_SRC

- now we can deploy to the swarm
#+BEGIN_SRC sh
docker stack deploy --compose-file docker-compose.yml mycustomstack
#+END_SRC
each service can now be administer individually

- confirm the services
#+BEGIN_SRC sh
docker service ls
docker service ps mycustomstack_apiweb1
docker service ps mycustomstack_apiweb2
docker service ps mycustomstack_load-balancer
#+END_SRC
the service name applied in the compose file is appended to the end

* Logs
- first place to look is /var/log/message or journalctl
#+BEGIN_SRC sh
cat /var/log/messages | grep -i "docker"
journal -e | grep -i "docker"
#+END_SRC

- check the logs of a specific container
#+BEGIN_SRC sh
docker container logs testweb
#+END_SRC

- check the logs of a whole service
#+BEGIN_SRC sh
docker service logs testweb
#+END_SRC
this will print the logs of all the nodes associated with the service

* Lecture
* Tutorials
** Linux Academy Lab - Installing Docker CE and Pulling Images
[[file://home/crito/Documents/SysAdmin/Virt/Docker/installing_docker-ce_lab.pdf][Installing Docker CE and Pulling Images for Container Utilization]]

* Books
[[file://home/crito/Documents/SysAdmin/Virt/Docker/docker_cheat-sheet.pdf][Linux Academy - Docker - Cheatsheet]]
[[file://home/crito/Documents/SysAdmin/Virt/Docker/Using_Docker.pdf][Using Docker]]
[[file://home/crito/Documents/SysAdmin/Virt/Docker/Pro_Docker.pdf][Pro Docker]]
[[file://home/crito/Documents/SysAdmin/Virt/Docker/Learning_Docker.pdf][Learning Docker]]
[[file://home/crito/Documents/SysAdmin/Virt/Docker/Monitoring_Docker.pdf][Monitoring Docker]]
[[file://home/crito/Documents/SysAdmin/Virt/Docker/Orchestrating_Docker.pdf][Orchestrating Docker]]
** [[file://home/crito/Documents/SysAdmin/Virt/Docker/Docker_Cookbook.pdf][Docker Cookbook]]
** Containers - Get Started Part 2
https://docs.docker.com/get-started/part2/
- app.py
#+BEGIN_EXAMPLE
from flask import Flask
from redis import Redis, RedisError
import os
import socket

# Connect to Redis
redis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)

app = Flask(__name__)

@app.route("/")
def hello():
    try:
        visits = redis.incr("counter")
    except RedisError:
        visits = "<i>cannot connect to Redis, counter disabled</i>"

    html = "<h3>Hello {name}!</h3>" \
           "<b>Hostname:</b> {hostname}<br/>" \
           "<b>Visits:</b> {visits}"
    return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=80)
#+END_EXAMPLE

- requirements.txt
#+BEGIN_EXAMPLE
Flask
Redis
#+END_EXAMPLE

- Create image using this directory's Dockerfile
#+BEGIN_SRC sh
docker build -t friendlyname .
#+END_SRC

- Run "friendlyname" mapping port 4000 to 80
#+BEGIN_SRC sh
docker run -p 4000:80 friendlyname
#+END_SRC

- Same thing, but in detached mode
#+BEGIN_SRC sh
docker run -d -p 4000:80 friendlyname
#+END_SRC

- See a list of all running containers
#+BEGIN_SRC sh
docker ps
#+END_SRC

- Gracefully stop the specified container
#+BEGIN_SRC sh
docker stop <hash>
#+END_SRC

- See a list of all containers, even the ones not running
#+BEGIN_SRC sh
docker ps -a
#+END_SRC

- Force shutdown of the specified container
#+BEGIN_SRC sh
docker kill <hash>
#+END_SRC

- Remove the specified container from this machine
#+BEGIN_SRC sh
docker rm <hash>
#+END_SRC

- Remove all containers from this machine
#+BEGIN_SRC sh
docker rm $(docker ps -a -q)
#+END_SRC

- Show all images on this machine
#+BEGIN_SRC sh
docker images -a
#+END_SRC

- Remove the specified image from this machine
#+BEGIN_SRC sh
docker rmi <imagename>
#+END_SRC

- Remove all images from this machine
#+BEGIN_SRC sh
docker rmi $(docker images -q)
#+END_SRC

- Log in this CLI session using your Docker credentials
#+BEGIN_SRC sh
docker login
#+END_SRC

- Tag <image> for upload to registry
#+BEGIN_SRC sh
docker tag <image> username/repository:tag
#+END_SRC

- Upload tagged image to registry
#+BEGIN_SRC sh
docker push username/repository:tag
#+END_SRC

- Run image from a registry
#+BEGIN_SRC sh
docker run username/repository:tag
#+END_SRC

** Services - Get Started Part 3
https://docs.docker.com/get-started/part2/

docker-compose.yml
#+BEGIN_EXAMPLE
version: "3"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: username/repository:tag
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "80:80"
    networks:
      - webnet
networks:
  webnet:
#+END_EXAMPLE

- Before you can call docker stack, swarm needs to to initiated
#+BEGIN_SRC sh
docker swarm init
#+END_SRC

- Now run the script
#+BEGIN_SRC sh
docker stack deploy -c docker-compose.yml getstartedlab
#+END_SRC

- See a list of 5 containers
#+BEGIN_SRC sh
docker stack ps getstartedlab
#+END_SRC
You can run curl http://localhost several times in a row, or go to that URL in your browser and hit refresh a few times. Either way, youll see the container ID change, demonstrating the load-balancing; with each request, one of the 5 replicas is chosen, in a round-robin fashion, to respond.

- To teardown the stack
#+BEGIN_SRC sh
docker stack rm getstartedlab
docker swarm leave --force
#+END_SRC

**** Cmds used
- List all running applications on this Docker host
#+BEGIN_SRC sh
docker stack ls
#+END_SRC

- Run the specified Compose file
#+BEGIN_SRC sh
docker stack deploy -c docker-compose.yml getstartedlab
#+END_SRC

- List the services associated with an app
#+BEGIN_SRC sh
docker stack services getstartedlab
#+END_SRC

- List the running containers associated with an app
#+BEGIN_SRC sh
docker stack ps getstartedlab
#+END_SRC

- Tear down an application
#+BEGIN_SRC sh
docker stack rm getstartedlab
#+END_SRC

* Links
