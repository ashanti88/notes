#+TAGS: sys anal


* Performance
* Tools & Applications
- [[file://home/crito/org/tech/cmds/top.org][top]]
- [[file://home/crito/org/tech/cmds/ps.org][ps]]
- [[file://home/crito/org/tech/cmds/dstat.org][dstat]]
- [[file://home/crito/org/tech/cmds/iostat.org][iostat]]
- [[file://home/crito/org/tech/cmds/vmstat.org][vmstat]]
- [[file://home/crito/org/tech/cmds/free.org][free]]
- [[file://home/crito/org/tech/cmds/perf.org][perf]]
- BPF
- [[file://home/crito/org/tech/monitoring/systemtap.org][SystemTap]]

* Tutorials
** Using Linux Performance Tools - O'Reilly
Github: https://github.com/goldshtn/linux-tracing-workshop

- The USE Method
Anti-Patterns
  - looking under the streetlight
  - "The Tools Method"
    - use random tools, because you have them
  - Assumptions, irrational beliefs
  - Blame someone else

U - Utilisation
S - Saturation
E - Errors

for each hard/software resource identify utilisation, saturation and errors

- The USE Checklist for Linux Systems
  http://www.brendangregg.com/USEmethod/use-linux.html
  this link provides component to tool

- Types of Performance Tools
  - Categorized by Depth
    - Counting tools (how many times?)
      - top, ifconfig
    - Latency tools (how long?)
      - iolatency, fileslower, dbslower
    - Stack aggregators (where from?)
      - perf, stackcount
    - Tracers
      - Logs, perf, trace
	
  - Categorized by Data Processing
    - Real-time
      - Output as events arrive
      - No long-term aggregation
      - Lower overhead
	
    - Later analysis
      - Aggregated or raw data written to a file
      - Post-processing required
      - Can go back and investigate

- Tracing Vs Sampling
  - Sampling works by getting a snapshot or a call stack every N occurrences of an interesting event.
  - Tracing works by getting a message or a call stack at every occurrence of an interesting event.(lower fequency)
    
  - Tools
    - SysDig
    - BPF
    - perf
    - SystemTap
    - ftrace
    - LTTng
      
- Kernel Tracepoints
  - Enbedded in the kernel at compile-time to trace events for various areas in the system
    - 1609 tracepoints in Linux 4.8
    - None in the TCP/IP stack
    - tracepoints can be found in /sys/kernel/debug/tracing/
      - each tracepoint has a format file and this provides more information.
      
  - Tracepoint usage
    - Summary of block device utilization and latency
    - Blocked process wait times and timeline
    - Kernel memory allocation patterns
    - Hardware interrupt handling and distribution
    - Application workload characterization through syscalls
    
- PMU Events
  - Performance Management Unit, provides processor performance counters
  - Availability on some VMs is limited
    - some virtualize the PMU (Xen, VMWare)
    - is available in EC2 dedicated hosts
      
- Processor Performance Counters senarios
  - Instructions retired
    - Find the IPC/CPI metric to understand if the application is using the CPU effectively
  - LLC (last level cache) misses
    - Detect algorithm inefficiencies or noisy neighbors
  - CPU port utilization
    - Understand how to better spread the workload between the processor's execution units
      
  - Collecting Processor Performance Counters
    - Performance counters can be read at predefined intervals
      - Read at start and end, subtract, get metric
    - For stack sampliing, can configure the processor to generate an interrup when a counter overfolows
      - E.g. grab a stack sample every 100K cache misses
	
- KProbes and UProbes
  - Dynamic Tracing
    - Tracepoints can't cover everything
      - some areas don't have tracepoints (TCP/UDP)
      - Somethime you really wish for another tracepoint, tracepoint isn't detailed enough
    - Dynamic tracing is about instrumenting arbitrary functions in kernel- or user-space
      - Count TCP segments sent/received
      - Trace failed memory allocations with allocation size
      - Aggregate database query text and latency
  - Probe Discovery
    - Unlike tracepoints, you need to find the function you're interested in - by reading the source
      - nm, objdump, /proc/kallsyms, perf and others can help
    - Function arguments, local variables and return values can also be recorded
      
- Listing Probe Locations
  - The OS kernel functions can be found in /proc/kallsyms
    - use grep to narrow your function search, as there are a huge amount
      
      
- USDT (User Statically Defined Tracing)
  - Brings kernel tracepoints to user programs
  - Tracepoint information and arguments embedded in the binary and available to tracing tools
  - Probes are nops until enabled (no overhead)

  - .d/.stp files (Dtrace and SystemTap)
    - these two tools are commonly used to access the data from the USDT
  
  - Finding USDT probes
    #+BEGIN_SRC sh
    readelf -n binary
    #+END_SRC
    - this will list descriptors embedded into the binary (stapsdt)
    - tplist is python script that makes the above output much more readable
      
- Introduction to Perf
debian
#+BEGIN_SRC sh
apt install linux-tools-common
#+END_SRC
rhel
#+BEGIN_SRC sh
yum install perf
#+END_SRC

- perf is a linux multi-tool for performance investigations
- developed in the kernel tree
  
- Example One-Liners
Record CPU Samples with stacks to find CPU hot path
#+BEGIN_SRC sh
perf record -ag -F 97
#+END_SRC

Probe user-space memory allocation failures with stacks
#+BEGIN_SRC sh
perf probe -x /lib64/libc.so.6 --add 'malloc%return res=$retval'
perf record -e probe:malloc --filter 'res==0' -g -p 188
#+END_SRC

Collect disk I/O access statistics and pinpoint heavy disk consumers
#+BEGIN_SRC sh
perf record -e block:block_rq_insert -a
#+END_SRC

Trac syscalls to find missing or excessive file operations
#+BEGIN_SRC sh
perf trace -e open
#+END_SRC

Get number of evernts over a time interval
#+BEGIN_SRC sh
perf stat -a -e sched:sched_switch -- sleep 5
#+END_SRC

Monitor system performance (like top) on 1000s of metrics
#+BEGIN_SRC sh
perf top
perf top -e block:block_rq_insert
perf top -e page_faults
#+END_SRC

- CPU Recording with Perf
- to find a CPU bottleneck, record stacks at timed intervals
system-wide
#+BEGIN_SRC sh
perf record -ag -F 97
#+END_SRC
a - all cpus
g - capture call stacks
F - frequency of samples /sec

specific process
#+BEGIN_SRC sh
perf record -p 188 -g -F 97
#+END_SRC
p - specific process

specific workload
#+BEGIN_SRC sh
perf record -g -F 97 -- ./myapp
#+END_SRC
-- - run workload and capture it

- Reading a flame Graph
  - A visualization method (adjacency graph), very useful for stack traces, invented by Brendan Gregg.
  - Turns millions of stack traces into an interactive graph
    - identify CPU hotspots on the system/application
    - show stacks that perform heavy disk accesses
    - find treads that block for a long time and the stack where they do it
      
- Generating Flame Graphs
  - Canonical flame graph generator
    - https://github.com/BrendanGregg/FlameGraph
  - Generators for other runtimes
    - go-torch
    - node-flame
    - pyflame
    - d3-flame-graph - d3js
      
  - Colorization
    - FlameGraph.pl has colour palettes for Java, C and other runtimes
      - this will allow you to disern what type of code is being called where visually

  - generate flame graph from perf script
    #+BEGIN_SRC sh
    perf script | stackcollapse-perf.pl | flamegraph.pl > flame_graph.svg
    #+END_SRC
    
* Books
** [[file://home/crito/Documents/SysAdmin/System/Systems_Performance.pdf][Systems Performance - Brendan Gregg]]

*** Latency
- Latency is the time take for a function or process to be performed.
- Its normally the best metric for analyising performance.
*** Dynamic Tracing
- first introduced in 2005 solaris 10 with dtrace.
  - been ported to OS X, BSD, and currently being ported to linux (systap is another alternative)
- dtrace has its own programming language D.
- Prior to dtrace, analysis was reliant on static probes.

*** Methodologies
**** Performance Terminology
  - IOPS - input/output operations per second
         - reads and writes per second
  - Throughput - the rate of work performed, data rate.
  - Response Time - the time for an operation to complete
  - Utilisation - measure of how busy a resource is over a given time
  - Saturation - the degree to which a resource has queued work it cannot service
  - Bottleneck - a resource that limits the performance of the system
  - Workload - the input to the system
             - for a database this includes queries and commands sent by the client
  - Cache - a fast storage area that can duplicate or buffer a limited amount of data
  - SUT - System Under Test
**** Latency of a website
The load time for a website can be broken down into 3 areas
1. DNS latency
2. TCP latency
3. TCP data transfer time
**** Common Trade offs
+ Filesystem record size 
  - Small record size - close to the application io size will perform better for random io workloads and make a more efficient fs cache while application is running.
  - Large record size - will improve streaming workloads, including fs backups 
+ Network buffer size
  - Small buffer size - reduce memory overhead for every connection
  - Large buffer size - improve network throughput
**** Metrics
+ IOPS
+ Throughput
+ Utilisation
+ Latency
The collection of these metrics will have an impact on the system, and add an overhead.
This is referred to as the observer effect.
***** Utilisation
This can be measured in two ways
1. time based
2. capacity based
Though knowing both would greatly help, normally only time based is available.
***** Saturation
Saturation occurs at 100% Utilisation (capacity based), extra work can not be processed so is queued.

**** Profiling
This builds a picture of the target so that it can be studied and understood.
The profile will be built be taking reading at different intervals

**** Caching 
Method to measure cache performance is cache hit-ratio - number of time the data was found in the cache (hit) vs the number of time not found (miss)
hit-ratio = hits/total accesses(hits and misses)
+ Alogrithms
  - MRU - Most recently used
  - LRU - Least recently used
  - MFU - Most fequently used
  - LFU - Least fequently used
+ Types of cache
  - Cold - empty or populated with unwanted data. Hit-ratio is zero
  - Hot - populated with commonly requested data. Hit-ratio is high
  - Warm - contains some requested data but not enought to be considered hot
  - Warmth - this describes how hot or cold a cache is

* Links
[[http://blog.tanelpoder.com/2013/02/21/peeking-into-linux-kernel-land-using-proc-filesystem-for-quickndirty-troubleshooting/][Peeking into Linux Kernel-land using /proc]]
[[https://opensource.com/article/17/11/bccbpf-performance][7 Useful Performance Analysis Tools for Linux]]
